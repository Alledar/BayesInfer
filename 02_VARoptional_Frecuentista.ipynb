{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAR frecuentista\n",
    "Seguiremos a [CEE2005](https://doi.org/10.1086/426038)\n",
    "\n",
    "CEE2005 calculan los efectos de la política monetaria convencional (PMC), para ello asumen:\n",
    "* Caracterización de la PMC: $$r_t = f(\\boldsymbol{\\Omega}_t) + \\epsilon_t$$ donde $\\Omega_t$ es el set de información utilizado por el BC para determinar la tasa de interés $R_t$\n",
    "\n",
    "* Los agregados monetarios son tales que la ecuación de arriba se satisface\n",
    "\n",
    "* Identificación: $\\epsilon_t$ es ortogonal a $\\boldsymbol{\\Omega}_t$\n",
    "\n",
    "* Definamos $\\mathbf{X}^s=\\{\\mathbf{x}_i\\}_{t=-\\infty}^{s}$ la historia del vector $\\mathbf{x}_i$ hasta el momento $s$, entonces $\\boldsymbol{\\Omega}_t$ es $$\\boldsymbol{\\Omega}^t\\equiv\\{\\mathbf{Y}_1^{t}\\ \\mathbf{Y}_2^{t-1}\\}$$\n",
    "\n",
    "* El VAR se puede especificar como: $\\mathbf{y}_t=[\\mathbf{y}_{1,t}\\ r_t\\ \\mathbf{y}_{2,t}]$ donde debido a que $\\mathbf{y}_{1,t}\\in \\boldsymbol{\\Omega}^t$, no responde a variaciones de $r_t$. Asimismo, como $\\mathbf{y}_{2,t}\\not\\in \\boldsymbol{\\Omega}^t$, responde a variaciones de $r_t$.\n",
    "\n",
    "Especificación:\n",
    "\n",
    "$$\\mathbf{y}_{1,t}=[gdp_t,\\ cons_t,\\ p_t^{def},\\ inv_t,\\ wage_t,\\ labprod_t]'$$\n",
    "\n",
    "$$\\mathbf{y}_{2,t}=[profits_t,\\ Growth^{M2}_t)]$$\n",
    "\n",
    "Todas las variables en logaritmos naturales excepto $Growth^{M2}_t$\n",
    "\n",
    "* Que tipo de identificación es esta?\n",
    "* Importa el orden de las variables dentro de $\\mathbf{y}_{1,t}$ e $\\mathbf{y}_{2,t}$?\n",
    "\n",
    "## Importar modulos requeridos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Algebra matricial\n",
    "import pandas as pd\n",
    "import random      # Simulacion aleatoria\n",
    "import matplotlib.pyplot as plt # gráficos\n",
    "import os\n",
    "import sys\n",
    "import VARstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed( 0 )    # Fijando la semilla (reproducir resultados)\n",
    "np.random.seed( 0 ) # Fijando la semilla (reproducir resultados)\n",
    "cwd = os.getcwd()\n",
    "sys.path.append(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "con ```pandas_datareader``` podemos extraer los datos directamente de las bases de datos de la FED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(1965,1,1)\n",
    "end   = datetime.datetime(2004,12,31)\n",
    "EFF  = web.DataReader('DFF', 'fred', start=start, end=end)\n",
    "EFF  = EFF.resample('Q').mean()\n",
    "index = EFF.index\n",
    "RGDP = web.DataReader('GDPC1', 'fred', start=start, end=end)\n",
    "CONS = web.DataReader('PCECC96', 'fred', start=start, end=end)\n",
    "DEF  = web.DataReader('GDPDEF', 'fred', start=start, end=end)\n",
    "RINV = web.DataReader('RINV', 'fred', start=start, end=end)\n",
    "TLP  = web.DataReader('ULQELP01USQ661S', 'fred', start=start, end=end)\n",
    "PRF  = web.DataReader('CP', 'fred', start=start, end=end)\n",
    "M2   = web.DataReader('MABMM201USQ189S', 'fred', start=datetime.datetime(1964,9,1), end=end)\n",
    "DM2  = (M2/M2.shift(1)).dropna()\n",
    "CPI  = web.DataReader('CPALTT01USQ661S', 'fred', start=start, end=end)\n",
    "\n",
    "RGDP.index = EFF.index\n",
    "CONS.index = EFF.index\n",
    "DEF.index = EFF.index\n",
    "RINV.index = EFF.index\n",
    "TLP.index = EFF.index\n",
    "PRF.index = EFF.index\n",
    "DM2.index = EFF.index\n",
    "CPI.index = EFF.index\n",
    "\n",
    "# Wages is downloaded from BLS as csv\n",
    "RWAG = pd.read_csv('BLS_Wage.csv')\n",
    "RWAG.index = RGDP.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfomando la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.log(RGDP)\n",
    "cc =  np.log(CONS)\n",
    "dd = np.log(DEF)\n",
    "ii = np.log(RINV)\n",
    "ww = np.log(RWAG)\n",
    "lp = np.log(TLP)\n",
    "rr = EFF\n",
    "rp = pd.DataFrame(np.log(PRF.values/CPI.values))\n",
    "rp.index = index\n",
    "dm = np.log(DM2)\n",
    "\n",
    "DF = pd.concat([ yy, cc,   dd,   ii, ww,  lp, rr,     rp,    dm],axis=1)\n",
    "DF.columns =   ['y','c','def','inv','w','lp','r', 'prof', 'dm2']\n",
    "\n",
    "data = DF.values\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimar\n",
    "Como en CEE2005 tomamos 4 rezagos (i.e., ```lag=4```) y construimos las matrices de acuerdo a sus definiciones en las diapositivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 4\n",
    "y,X,k,Tf = VARstuff.get_yXform(data,lag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimación MCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bhat,Sigmahat,yhat,uhat = VARstuff.get_MCO_VAR(y,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pronóstico\n",
    "Utilizaremos la función que simula VARs para obtener pronósticos\n",
    "\n",
    "* Si simulamos el VAR con punto inicial a las primeras $p$ observaciones en la data y con los residuos estimados, deberiamos replicar toda la data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = X[0,:]\n",
    "yrep,Xrep = VARstuff.get_sim_VAR(X0,uhat,Bhat,lag)\n",
    "np.linalg.norm(y-yrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cortemos la muestra 2 años antes del fin de los datos para estimar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 2*4\n",
    "yhist = y[:(Tf-H-1),:]\n",
    "Xhist = X[:(Tf-H-1),:]\n",
    "Bhat_hist,Sigmahat_hist,yhat_hist,uhat_hist = VARstuff.get_MCO_VAR(yhist,Xhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtp1 = X[(Tf-H-1),:] # Punto inicial para pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = y[(Tf-H-1):,:]\n",
    "ytrue_first = np.reshape(ytrue[0,:],(1,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_zero = np.zeros(shape=(H,k)) # sin choques en el horizonte de proyección\n",
    "y_zero,_ = VARstuff.get_sim_VAR(Xtp1,u_zero,Bhat_hist,lag)\n",
    "y_zero = np.r_[ytrue_first,y_zero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yt = ytrue_first\n",
    "n=10**3\n",
    "Fore_BT = VARstuff.get_Fore_BT(yt,Xtp1,uhat_hist,Bhat,lag,H,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ForeBT_Q95  = np.percentile(Fore_BT, 95, axis=2)\n",
    "ForeBT_Q05  = np.percentile(Fore_BT,  5, axis=2)\n",
    "ForeBT_mean = np.mean(Fore_BT,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = 12.75+np.array(range(9))/4+0.125\n",
    "varnames = ['PBI','Consumo','Deflactor','Inversion','Salarios','Labor Prod.','Tasa de interes', 'Utilidades', 'Crec. M2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "\n",
    "ff = 0\n",
    "for rr in range(3):\n",
    "    for cc in range(3):\n",
    "        axs[rr,cc].plot(quarters,ytrue[:,ff],'k')\n",
    "        axs[rr,cc].plot(quarters,y_zero[:,ff],'b')\n",
    "        axs[rr,cc].plot(quarters,ForeBT_mean[:,ff],'r')\n",
    "        axs[rr,cc].plot(quarters,ForeBT_Q05[:,ff],'--r')\n",
    "        axs[rr,cc].plot(quarters,ForeBT_Q95[:,ff],'--r')\n",
    "        axs[rr,cc].set_title(varnames[ff])\n",
    "        axs[rr,cc].autoscale(enable=True, axis='both', tight=True)\n",
    "        ff += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impulso respuesta\n",
    "Identificación por Cholesky\n",
    "\n",
    "### IRF simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 4*5    # 4 años\n",
    "shock = 7  # 'r' en posición 7\n",
    "scale = -1 # choque negativo de tasa (# de STDs)\n",
    "IRF = VARstuff.get_IRF_Chol(Bhat,Sigmahat,h,shock,k,lag,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "\n",
    "ff = 0\n",
    "for rr in range(3):\n",
    "    for cc in range(3):\n",
    "        axs[rr,cc].plot(IRF[ff,:])\n",
    "        axs[rr,cc].axhline(0, color='green')\n",
    "        axs[rr,cc].set_title(varnames[ff]+' to r')\n",
    "        axs[rr,cc].autoscale(enable=True, axis='both', tight=True)\n",
    "        ff += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalo de confianza: Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample = 10**3\n",
    "IRF_BT = VARstuff.get_IRF_Chol_BT(y,X,k,Tf,nsample,h,shock,lag,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRFBT_Q95  = np.percentile(IRF_BT, 95, axis=2)\n",
    "IRFBT_Q05  = np.percentile(IRF_BT,  5, axis=2)\n",
    "IRFBT_mean = np.mean(IRF_BT,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "\n",
    "ff = 0\n",
    "for rr in range(3):\n",
    "    for cc in range(3):\n",
    "        axs[rr,cc].plot(IRFBT_mean[ff,:])\n",
    "        axs[rr,cc].plot(IRFBT_Q95[ff,:],'r')\n",
    "        axs[rr,cc].plot(IRFBT_Q05[ff,:],'r')\n",
    "        axs[rr,cc].axhline(0, color='green')\n",
    "        axs[rr,cc].set_title(varnames[ff]+' to r')\n",
    "        axs[rr,cc].autoscale(enable=True, axis='both', tight=True)\n",
    "        ff += 1\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "> Christiano, Eichenbaum and Evans, *Nominal Rigidities and the Dynamic Effects of a Shock to Monetary Policy*, Journal of Political Economy [https://doi.org/10.1086/426038](https://doi.org/10.1086/426038)\n",
    "\n",
    "> Lütkepohl, Helmut, 2005. *New introduction to multiple time series analysis*. Springer Berlin Heidelberg. [https://www.springer.com/gp/book/9783540401728](https://www.springer.com/gp/book/9783540401728)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
